import os
import json
import cv2
import numpy as np
import datetime
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from insightface.app import FaceAnalysis

# ArcFace ëª¨ë¸ ë¡œë“œ
app = FaceAnalysis(name="buffalo_l")
app.prepare(ctx_id=-1)  # CPU ì‚¬ìš©

# YOLO ëª¨ë¸ ë¡œë“œ
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
YOLO_WEIGHTS = os.path.join(BASE_DIR, "model", "yolov4-tiny.weights")
YOLO_CFG = os.path.join(BASE_DIR, "model", "yolov4-tiny.cfg")

# ì„ë² ë”© ì €ì¥ ê²½ë¡œ
EMBEDDING_DIR = os.path.join(BASE_DIR, "embeddings")
DETECTED_DIR = os.path.join(BASE_DIR, "detected")
os.makedirs(EMBEDDING_DIR, exist_ok=True)  # í´ë” ìƒì„±
os.makedirs(DETECTED_DIR, exist_ok=True)  # í´ë” ìƒì„±

@csrf_exempt
def verify_face(request):
    """ ì—…ë¡œë“œëœ ì–¼êµ´ì„ ë“±ë¡ëœ ì–¼êµ´ê³¼ ë¹„êµí•˜ì—¬ ì¸ì¦ ë° ì–¼êµ´ ì €ì¥ """
    if request.method != "POST":
        return JsonResponse({"status": "error", "message": "ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤."}, status=405)

    if "face_image" not in request.FILES or "user_id" not in request.POST:
        return JsonResponse({"status": "error", "message": "ì‚¬ìš©ì ID ë˜ëŠ” ì´ë¯¸ì§€ ë°ì´í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."}, status=400)

    user_id = request.POST["user_id"].strip()
    embedding_path = os.path.join(EMBEDDING_DIR, f"{user_id}_embedding.json")

    if not os.path.exists(embedding_path):
        return JsonResponse({"status": "error", "message": "í•´ë‹¹ IDì˜ ì–¼êµ´ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}, status=404)

    # âœ… ì €ì¥ëœ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°
    with open(embedding_path, "r") as f:
        stored_embedding = np.array(json.load(f))

    # âœ… ì—…ë¡œë“œëœ ì–¼êµ´ ì´ë¯¸ì§€ ì²˜ë¦¬
    image_file = request.FILES["face_image"]
    image_bytes = image_file.read()
    nparr = np.frombuffer(image_bytes, np.uint8)
    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    if image is None:
        print("âŒ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨!")
        return JsonResponse({"status": "error", "message": "ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, status=400)

    # âœ… YOLOë¥¼ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ
    faces = detect_face(image)
    if len(faces) == 0:
        print("âŒ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨! YOLOê°€ ì–¼êµ´ì„ ì°¾ì§€ ëª»í•¨.")
        return JsonResponse({"status": "error", "message": "ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}, status=400)

    print(f"âœ… ê°ì§€ëœ ì–¼êµ´ ê°œìˆ˜: {len(faces)}")

    highest_similarity = -1
    best_match = None
    now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

    for i, (x, y, w, h) in enumerate(faces):
        # ğŸš€ ì¢Œí‘œ ë³´ì • (ìŒìˆ˜ ë° ì´ë¯¸ì§€ ê²½ê³„ ì´ˆê³¼ ë°©ì§€)
        x = max(0, x)
        y = max(0, y)
        w = min(w, image.shape[1] - x)
        h = min(h, image.shape[0] - y)

        # ğŸš€ ì–¼êµ´ í¬ê¸° ê²€ì¦
        if w < 20 or h < 20:
            print(f"âŒ ì–¼êµ´ í¬ë¡­ ì‹¤íŒ¨! (index {i}) ê°ì§€ëœ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ. (w={w}, h={h})")
            continue

        face_crop = image[y:y+h, x:x+w]

        if face_crop.size == 0:
            print(f"âŒ ì–¼êµ´ í¬ë¡­ ì‹¤íŒ¨! (index {i}) YOLOì˜ ì¢Œí‘œê°€ ì˜ëª»ë¨.")
            continue

        face_crop = cv2.resize(face_crop, (112, 112))
        face_crop = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)

        # âœ… ê°ì§€ëœ ì–¼êµ´ì„ íŒŒì¼ë¡œ ì €ì¥
        save_path = os.path.join(DETECTED_DIR, f"{now}_{i}.jpg")
        cv2.imwrite(save_path, face_crop)
        print(f"ğŸ“¸ ì–¼êµ´ ì €ì¥ ì™„ë£Œ: {save_path}")

        # âœ… ArcFaceë¡œ ì„ë² ë”© ì¶”ì¶œ
        face_data = app.get(np.asarray(face_crop))
        if len(face_data) == 0:
            print(f"âŒ ArcFaceê°€ ì–¼êµ´ì„ ì¸ì‹í•˜ì§€ ëª»í•¨! (index {i})")
            continue

        uploaded_embedding = np.array(face_data[0].normed_embedding)

        # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = np.dot(uploaded_embedding, stored_embedding)

        print(f"ğŸ§ ì–¼êµ´ ë¹„êµ (index {i}) - ìœ ì‚¬ë„: {similarity:.4f}")

        # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ ê¸°ë¡
        if similarity > highest_similarity:
            highest_similarity = similarity
            best_match = similarity

        # âœ… ì–¼êµ´ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)
        cv2.putText(image, f"{similarity:.3f}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # âœ… ê°ì§€ëœ ì–¼êµ´ì´ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ì €ì¥
    debug_image_path = os.path.join(DETECTED_DIR, f"{now}_detected.jpg")
    cv2.imwrite(debug_image_path, image)
    print(f"ğŸ–¼ ê°ì§€ëœ ì–¼êµ´ ë°•ìŠ¤ ì €ì¥ ì™„ë£Œ: {debug_image_path}")

    # âœ… ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¸ì¦ ì„±ê³µ ì—¬ë¶€ ê²°ì •
    if best_match is not None and best_match > 0.5:
        return JsonResponse({
            "status": "success",
            "message": "ì¸ì¦ ì„±ê³µ! ë™ì¼í•œ ì–¼êµ´ì…ë‹ˆë‹¤.",
            "similarity": float(best_match),
            "saved_faces": debug_image_path
        })

    return JsonResponse({
        "status": "fail",
        "message": "ì¸ì¦ ì‹¤íŒ¨! ì¼ì¹˜í•˜ëŠ” ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "similarity": float(highest_similarity) if best_match is not None else 0,
        "saved_faces": debug_image_path
    })


def detect_face(image):
    """ YOLOë¥¼ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ ë° ì¤‘ë³µ ì œê±° (NMS ì ìš©) """
    YOLO_NET = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WEIGHTS)
    YOLO_NET.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
    YOLO_NET.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

    height, width = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)
    YOLO_NET.setInput(blob)
    outputs = YOLO_NET.forward(YOLO_NET.getUnconnectedOutLayersNames())

    boxes = []
    confidences = []
    
    for output in outputs:
        for detection in output:
            scores = detection[5:]  # í´ë˜ìŠ¤ ì‹ ë¢°ë„ ê°’ë“¤
            confidence = max(scores)  # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ
            if confidence > 0.6:  # ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •
                center_x, center_y, w, h = (detection[:4] * np.array([width, height, width, height])).astype("int")
                x, y = int(center_x - w / 2), int(center_y - h / 2)
                
                # ë°•ìŠ¤ì™€ ì‹ ë¢°ë„ ì¶”ê°€
                boxes.append([x, y, w, h])
                confidences.append(float(confidence))

    # âœ… NMS ì ìš©í•˜ì—¬ ì¤‘ë³µëœ ë°•ìŠ¤ ì œê±°
    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    final_faces = []
    if len(indices) > 0:
        for i in indices.flatten():
            final_faces.append(boxes[i])

    return final_faces