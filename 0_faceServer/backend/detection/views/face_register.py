import os
import json
import cv2
import numpy as np
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from insightface.app import FaceAnalysis

# ArcFace ëª¨ë¸ ë¡œë“œ
app = FaceAnalysis(name="buffalo_l")
app.prepare(ctx_id=-1)  # CPU ì‚¬ìš© (GPUëŠ” ctx_id=0)

# YOLO ëª¨ë¸ ë¡œë“œ
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
YOLO_WEIGHTS = os.path.join(BASE_DIR, "model", "yolov4-tiny.weights")
YOLO_CFG = os.path.join(BASE_DIR, "model", "yolov4-tiny.cfg")

YOLO_NET = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WEIGHTS)
YOLO_NET.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
YOLO_NET.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

# ì €ì¥ ê²½ë¡œ ì„¤ì •
EMBEDDING_DIR = os.path.join(BASE_DIR, "embeddings")
os.makedirs(EMBEDDING_DIR, exist_ok=True)

MAX_CAPTURE = 5  # ğŸš€ 5ì¥ì˜ ì‚¬ì§„ìœ¼ë¡œ í‰ê·  ì„ë² ë”© ìƒì„±


@csrf_exempt
def register_face(request):
    """ ì‚¬ìš©ìì˜ ì–¼êµ´ì„ 5ì¥ ì´¬ì˜í•˜ì—¬ í‰ê·  ì„ë² ë”©ì„ ì €ì¥í•˜ëŠ” API """
    if request.method != "POST":
        return JsonResponse({"status": "error", "message": "ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤."}, status=405)

    user_id = request.POST.get("user_id", "unknown")
    images = request.FILES.getlist("face_images")

    if not images:
        return JsonResponse({"status": "error", "message": "ì´ë¯¸ì§€ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}, status=400)

    embeddings_list = []

    for index, image_file in enumerate(images):
        image_bytes = image_file.read()
        nparr = np.frombuffer(image_bytes, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        # YOLO ì–¼êµ´ ê°ì§€
        faces = detect_face(image)
        if len(faces) == 0:
            print(f"âŒ {index + 1}/{len(images)}: ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨")
            continue  # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ìŠ¤í‚µ

        # ArcFace ì„ë² ë”© ì¶”ì¶œ (ì²« ë²ˆì§¸ ì–¼êµ´ë§Œ)
        x, y, w, h = faces[0]
        face_crop = image[y:y+h, x:x+w]  
        face_crop = cv2.resize(face_crop, (112, 112))
        face_crop = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)

        face_data = app.get(np.asarray(face_crop))
        if len(face_data) > 0:
            embeddings_list.append(face_data[0].normed_embedding)
            print(f"âœ… {index + 1}/{len(images)}: ì–¼êµ´ ì„ë² ë”© ì €ì¥ë¨ ({len(embeddings_list)}/{MAX_CAPTURE})")

        if len(embeddings_list) >= MAX_CAPTURE:
            break  # 5ê°œ ì„ë² ë”©ë§Œ ì‚¬ìš©

    if len(embeddings_list) == 0:
        return JsonResponse({"status": "error", "message": "ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}, status=400)

    # í‰ê·  ì„ë² ë”© ìƒì„± ë° ì €ì¥
    avg_embedding = np.mean(embeddings_list, axis=0).tolist()
    embedding_path = os.path.join(EMBEDDING_DIR, f"{user_id}_embedding.json")

    with open(embedding_path, "w") as f:
        json.dump(avg_embedding, f, indent=4)

    return JsonResponse({
        "message": "ì–¼êµ´ ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
        "embedding_path": embedding_path,
        "embedding_count": len(embeddings_list)  # âœ… ì§„í–‰ ìƒí™© ì‘ë‹µì— í¬í•¨
    })


def detect_face(image):
    """ YOLOë¥¼ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ ë° bounding box ë°˜í™˜ """
    height, width = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)
    YOLO_NET.setInput(blob)
    outputs = YOLO_NET.forward(YOLO_NET.getUnconnectedOutLayersNames())

    faces = []
    for output in outputs:
        for detection in output:
            confidence = detection[5]
            if confidence > 0.5:
                center_x, center_y, w, h = (detection[:4] * np.array([width, height, width, height])).astype("int")
                x, y = int(center_x - w / 2), int(center_y - h / 2)
                faces.append((x, y, w, h))

    return faces
